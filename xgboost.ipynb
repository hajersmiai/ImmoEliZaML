{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "#from  typing import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import sparse\n",
    "#!pip install xgboost optuna scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e69a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE (test): 52528712657.64994\n",
      "R2 Score (test): 0.7990916265311266\n",
      "R2 Score (train): 0.8376644338462151\n",
      "MAE (test): 112546.4594272763\n",
      "MAE (train): 107312.24248498713\n",
      "MAPE (test): 0.25560821305746084\n",
      "MAPE (train): 0.2515677916508978\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/nonull_smalldata.csv\")\n",
    "df.columns\n",
    "df.dtypes\n",
    "numeric_columns=[\"bedroomCount\",\"toilet_and_bath\",\"habitableSurface\",\"facedeCount\",\"hasTerrace\",\"totalParkingCount\"]\n",
    "categorical_columns=[\"type\",\"subtype\",\"province\",\"locality\",\"postCode\",\"buildingCondition\",\"epcScore\"]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "df = pd.concat([df, one_hot_df], axis=1)\n",
    "df = df.drop(categorical_columns, axis=1)\n",
    "#df.to_csv(\"data/imputed_encoded_data.csv\")\n",
    "\n",
    "X=df.drop(columns=\"price\")\n",
    "y=df[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=1234)\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled= scaler.transform(X_test)\n",
    "#X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "#X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "X_train = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "xgb_regressor = XGBRegressor(\n",
    "    objective='reg:squarederror', # For regression tasks, specify the objective\n",
    "    n_estimators=180,             # Number of boosting rounds\n",
    "    learning_rate=0.1,            # Step size shrinkage\n",
    "    max_depth=4,                  # Maximum depth of a tree\n",
    "    subsample=0.6,                # Subsample ratio of the training instance\n",
    "    colsample_bytree=0.6,         # Subsample ratio of columns\n",
    "    random_state=42,              # For reproducibility\n",
    "    n_jobs=-1                     # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "train_preds = xgb_regressor.predict(X_train)\n",
    "test_preds = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate using stored predictions\n",
    "print(\"XGBoost MSE (test):\", mean_squared_error(y_test, test_preds))\n",
    "print(\"R2 Score (test):\", r2_score(y_test, test_preds))\n",
    "print(\"R2 Score (train):\", r2_score(y_train, train_preds))\n",
    "print(\"MAE (test):\", mean_absolute_error(y_test, test_preds))\n",
    "print(\"MAE (train):\", mean_absolute_error(y_train, train_preds))\n",
    "print(\"MAPE (test):\", mean_absolute_percentage_error(y_test, test_preds))\n",
    "print(\"MAPE (train):\", mean_absolute_percentage_error(y_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1af571",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1, 10]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42, n_jobs=2)\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=5,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
