{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff521eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "#from  typing import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import sparse\n",
    "from lightgbm import early_stopping, log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37068cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's rmse: 234106\n",
      "[200]\tvalid's rmse: 225897\n",
      "[300]\tvalid's rmse: 222395\n",
      "[400]\tvalid's rmse: 220236\n",
      "[500]\tvalid's rmse: 218864\n",
      "[600]\tvalid's rmse: 218499\n",
      "[700]\tvalid's rmse: 217335\n",
      "[800]\tvalid's rmse: 216737\n",
      "Early stopping, best iteration is:\n",
      "[848]\tvalid's rmse: 216615\n",
      "\n",
      "ðŸ“Š Evaluation Metrics:\n",
      "MSE (test): 46921995587.74079\n",
      "RÂ² (train): 0.8557609783870117\n",
      "RÂ² (test): 0.8205358300918923\n",
      "MAE (train): 94178.061952273\n",
      "MAE (test): 102439.42029653097\n",
      "MAPE (train): 0.2096319497680936\n",
      "MAPE (test): 0.2224225398987471\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/nonull_cleaned_data.csv\")\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_columns = [\"bedroomCount\", \"toilet_and_bath\", \"habitableSurface\", \"facedeCount\", \"hasTerrace\", \"totalParkingCount\"]\n",
    "categorical_columns = [\"type\", \"subtype\", \"province\", \"locality\", \"postCode\", \"buildingCondition\", \"epcScore\"]\n",
    "\n",
    "# Fill missing categorical values with \"nan\" and convert to string\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype(str).fillna(\"nan\")\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "encoded = encoder.fit_transform(df[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "# Check for duplicates:\n",
    "def merge_duplicate_columns(df):\n",
    "    # Group columns by name and sum their values\n",
    "    df_merged = df.groupby(df.columns, axis=1).sum()\n",
    "    return df_merged\n",
    "# After one-hot encoding\n",
    "encoded_df.columns = encoded_df.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "# Merge duplicate columns by summing\n",
    "encoded_df = encoded_df.groupby(encoded_df.columns, axis=1).sum()\n",
    "# Combine features\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Combine features (X only, without target)\n",
    "X = pd.concat([df[numeric_columns], encoded_df], axis=1)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")\n",
    "\n",
    "# LightGBM dataset objects\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Train model with early stopping\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[val_data],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "train_preds = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "test_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nðŸ“Š Evaluation Metrics:\")\n",
    "print(\"MSE (test):\", mean_squared_error(y_test, test_preds))\n",
    "print(\"RÂ² (train):\", r2_score(y_train, train_preds))\n",
    "print(\"RÂ² (test):\", r2_score(y_test, test_preds))\n",
    "print(\"MAE (train):\", mean_absolute_error(y_train, train_preds))\n",
    "print(\"MAE (test):\", mean_absolute_error(y_test, test_preds))\n",
    "print(\"MAPE (train):\", mean_absolute_percentage_error(y_train, train_preds))\n",
    "print(\"MAPE (test):\", mean_absolute_percentage_error(y_test, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
